{"cells":[{"cell_type":"code","source":["! if [ ! -f tf_scenery.zip ]; then wget \"https://drive.google.com/uc?export=download&id=1XcL0guFyqhLns_HgkFBEKEpbUHQ1dA6U&confirm=yes\" -O tf_scenery.zip; unzip tf_scenery.zip; fi"],"metadata":{"id":"rDbxfSM8vGRP","executionInfo":{"status":"ok","timestamp":1703266389315,"user_tz":300,"elapsed":152,"user":{"displayName":"Chris Sibbitt","userId":"00854878476520643924"}}},"id":"rDbxfSM8vGRP","execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('./drive')"],"metadata":{"id":"D0qWNIhCtN2y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703266390204,"user_tz":300,"elapsed":899,"user":{"displayName":"Chris Sibbitt","userId":"00854878476520643924"}},"outputId":"8ac3abac-f982-4193-cdc4-e2d4c25c90f8"},"id":"D0qWNIhCtN2y","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at ./drive; to attempt to forcibly remount, call drive.mount(\"./drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":3,"id":"6e0ecc01-776d-423f-b305-90df9e358b0c","metadata":{"id":"6e0ecc01-776d-423f-b305-90df9e358b0c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703266419802,"user_tz":300,"elapsed":29602,"user":{"displayName":"Chris Sibbitt","userId":"00854878476520643924"}},"outputId":"e246300f-1074-4f09-9dff-caed5dbf68e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.10/dist-packages (0.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (23.2)\n","Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (2.13.3)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n","\n","TensorFlow Addons (TFA) has ended development and introduction of new features.\n","TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n","Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n","\n","For more information see: https://github.com/tensorflow/addons/issues/2807 \n","\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.13.0 and strictly below 2.16.0 (nightly versions are not supported). \n"," The versions of TensorFlow you are currently using is 2.12.0 and is not supported. \n","Some things might work, some things might not.\n","If you were to encounter a bug, do not file an issue.\n","If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n","You can find the compatibility matrix in TensorFlow Addon's readme:\n","https://github.com/tensorflow/addons\n","  warnings.warn(\n"]}],"source":["!pip install tensorflow-addons\n","import random\n","import os\n","import sys\n","sys.path.append('./drive/MyDrive/v2_NS-Outpainting')\n","from glob import glob\n","import numpy as np\n","from PIL import Image\n","import tensorflow as tf\n","from tensorflow.python.training.moving_averages import assign_moving_average\n","from modeling.model import Model\n","from modeling.loss import Loss\n","from dataset.parse import parse_trainset, parse_testset\n","import argparse"]},{"cell_type":"code","execution_count":4,"id":"db68f1be-56b2-485c-a5af-3fc0d8065299","metadata":{"id":"db68f1be-56b2-485c-a5af-3fc0d8065299","executionInfo":{"status":"ok","timestamp":1703266419803,"user_tz":300,"elapsed":39,"user":{"displayName":"Chris Sibbitt","userId":"00854878476520643924"}}},"outputs":[],"source":["parser = argparse.ArgumentParser(description='Model training.')\n","# experiment\n","parser.add_argument('--date', type=str, default='1221')\n","parser.add_argument('--exp-index', type=int, default=1)\n","parser.add_argument('--f', action='store_true', default=False)\n","\n","# gpu\n","parser.add_argument('--start-gpu', type=int, default=0)\n","parser.add_argument('--num-gpu', type=int, default=2)\n","\n","# dataset\n","parser.add_argument('--trainset-path', type=str, default='./dataset/trainset.tfr')\n","parser.add_argument('--testset-path', type=str, default='./dataset/testset.tfr')\n","parser.add_argument('--trainset-length', type=int, default=5041)\n","parser.add_argument('--testset-length', type=int, default=2000)  # we flip every image in testset\n","\n","# training\n","parser.add_argument('--base-lr', type=float, default=0.0001)\n","parser.add_argument('--batch-size', type=int, default=32)\n","parser.add_argument('--weight-decay', type=float, default=0.00002)\n","parser.add_argument('--epoch', type=int, default=1500)\n","parser.add_argument('--lr-decay-epoch', type=int, default=1000)\n","parser.add_argument('--critic-steps', type=int, default=3)\n","parser.add_argument('--warmup-steps', type=int, default=1000)\n","parser.add_argument('--workers', type=int, default=2)\n","parser.add_argument('--clip-gradient', action='store_true', default=False)\n","parser.add_argument('--clip-gradient-value', type=float, default=0.1)\n","\n","\n","# modeling\n","parser.add_argument('--beta', type=float, default=0.9)\n","parser.add_argument('--lambda-gp', type=float, default=10)\n","parser.add_argument('--lambda-rec', type=float, default=0.998)\n","\n","# checkpoint\n","parser.add_argument('--log-path', type=str, default='./logs/')\n","parser.add_argument('--checkpoint-path', type=str, default=None)\n","parser.add_argument('--resume-step', type=int, default=0)\n","\n","args = parser.parse_args(['--f', '--trainset-path', './tf_dataset_new/trainset.tfr', '--testset-path', './tf_dataset_new/testset.tfr', '--log-path', './drive/MyDrive/v2_NS-Outpainting/logs/', '--batch-size', '4', '--num-gpu', '8']) #, '--checkpoint-path', './drive/MyDrive/v2_NS-Outpainting/logs/1221/1/models/-24963', '--resume-step', '24963'])"]},{"cell_type":"markdown","source":[],"metadata":{"id":"eJ2n-bspit2z"},"id":"eJ2n-bspit2z"},{"cell_type":"code","execution_count":5,"id":"9e7bf839-96fb-4050-87c6-52b0e34b54c3","metadata":{"id":"9e7bf839-96fb-4050-87c6-52b0e34b54c3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703266419918,"user_tz":300,"elapsed":152,"user":{"displayName":"Chris Sibbitt","userId":"00854878476520643924"}},"outputId":"e113d1e6-c9e6-4c86-f0fe-c0eda766eadb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Start Exp: 1221/1\n"]}],"source":["# prepare path\n","base_path = args.log_path\n","exp_date = args.date\n","if exp_date is None:\n","    print('Exp date error!')\n","    import sys\n","    sys.exit()\n","exp_name = exp_date + '/' + str(args.exp_index)\n","print(\"Start Exp:\", exp_name)\n","output_path = base_path + exp_name + '/'\n","model_path = output_path + 'models/'\n","tensorboard_path = output_path + 'log/'\n","result_path = output_path + 'results/'\n","\n","if not os.path.exists(model_path):\n","    os.makedirs(model_path)\n","if not os.path.exists(tensorboard_path):\n","    os.makedirs(tensorboard_path)\n","if not os.path.exists(result_path):\n","    os.makedirs(result_path)\n","elif not args.f:\n","    if args.checkpoint_path is None:\n","        print('Exp exist!')\n","        import sys\n","        sys.exit()\n","else:\n","    import shutil\n","    shutil.rmtree(model_path)\n","    os.makedirs(model_path)\n","    shutil.rmtree(tensorboard_path)\n","    os.makedirs(tensorboard_path)"]},{"cell_type":"code","execution_count":6,"id":"c761d337-c924-4396-b3e8-fca323054d00","metadata":{"id":"c761d337-c924-4396-b3e8-fca323054d00","executionInfo":{"status":"ok","timestamp":1703266419919,"user_tz":300,"elapsed":5,"user":{"displayName":"Chris Sibbitt","userId":"00854878476520643924"}}},"outputs":[],"source":["# prepare gpu\n","num_gpu = args.num_gpu\n","start_gpu = args.start_gpu\n","gpu_id = str(start_gpu)\n","for i in range(num_gpu - 1):\n","    gpu_id = gpu_id + ',' + str(start_gpu + i + 1)\n","os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)\n","args.batch_size_per_gpu = int(args.batch_size / args.num_gpu)"]},{"cell_type":"code","execution_count":7,"id":"f12515d6-32c6-4611-8da1-3e8922f8b2f3","metadata":{"id":"f12515d6-32c6-4611-8da1-3e8922f8b2f3","colab":{"base_uri":"https://localhost:8080/","height":757},"executionInfo":{"status":"error","timestamp":1703266448450,"user_tz":300,"elapsed":28535,"user":{"displayName":"Chris Sibbitt","userId":"00854878476520643924"}},"outputId":"c0b85138-c2a9-40c3-f983-b4c4ac8a660e"},"outputs":[{"output_type":"stream","name":"stdout","text":["All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\n","Start building model...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:From <ipython-input-7-9cc751e921be>:31: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This is a deprecated API that should only be used in TF 1 graph mode and legacy TF 2 graph mode available through `tf.compat.v1`. In all other situations -- namely, eager mode and inside `tf.function` -- you can consume dataset elements using `for elem in dataset: ...` or by explicitly creating iterator via `iterator = iter(dataset)` and fetching its elements via `values = next(iterator)`. Furthermore, this API is not available in TF 2. During the transition from TF 1 to TF 2 you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)` to create a TF 1 graph mode style iterator for a dataset created through TF 2 APIs. Note that this should be a transient state of your code base as there are in general no guarantees about the interoperability of TF 1 and TF 2 code.\n"]},{"output_type":"stream","name":"stdout","text":["build model on gpu tower\n","tower_0\n"]},{"output_type":"stream","name":"stderr","text":["/content/./drive/MyDrive/v2_NS-Outpainting/modeling/model.py:156: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n","  lstm_cell = tf.compat.v1.nn.rnn_cell.LSTMCell(\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n","WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/rnn/legacy_cells.py:1042: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","/content/./drive/MyDrive/v2_NS-Outpainting/modeling/model.py:168: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n","  lstm_cell = tf.compat.v1.nn.rnn_cell.BasicLSTMCell(\n","WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:At least two cells provided to MultiRNNCell are the same object and will share weights.\n","/content/./drive/MyDrive/v2_NS-Outpainting/modeling/model.py:396: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n","  logit = tf.compat.v1.layers.dense(tf.reshape(\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-9cc751e921be>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mloss_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_reconstruction_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroundtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                     \u001b[0mloss_adv_G\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_adv_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_and_local_adv_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroundtruth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                     \u001b[0mreg_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREGULARIZATION_LOSSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/./drive/MyDrive/v2_NS-Outpainting/modeling/loss.py\u001b[0m in \u001b[0;36mglobal_and_local_adv_loss\u001b[0;34m(self, model, gt, recon)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft_half_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_half_recon\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mglobal_D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_G\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_adversarial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_adversarial_global\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mright_half_gt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/./drive/MyDrive/v2_NS-Outpainting/modeling/loss.py\u001b[0m in \u001b[0;36mglobal_adversarial_loss\u001b[0;34m(self, dis_fun, real, fake)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mglobal_adversarial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madversarial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdis_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'DIS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlocal_adversarial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/./drive/MyDrive/v2_NS-Outpainting/modeling/loss.py\u001b[0m in \u001b[0;36madversarial_loss\u001b[0;34m(self, dis_fun, real, fake, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madversarial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdis_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0madversarial_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0madversarial_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTO_REUSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/./drive/MyDrive/v2_NS-Outpainting/modeling/model.py\u001b[0m in \u001b[0;36mbuild_adversarial_global\u001b[0;34m(self, img, reuse, name)\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInstanceNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             logit = tf.compat.v1.layers.dense(tf.reshape(\n\u001b[0m\u001b[1;32m    397\u001b[0m                 img, [bs, -1]), 1, activation=None)\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/legacy_tf_layers/core.py\u001b[0m in \u001b[0;36mdense\u001b[0;34m(inputs, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     )\n\u001b[0;32m--> 274\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/legacy_tf_layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m                     \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m                     \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m                     \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer_v1.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2180\u001b[0m                 \u001b[0;31m# later pollute any eager operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2181\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2182\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2183\u001b[0m             \u001b[0;31m# We must set also ensure that the layer is marked as built, and the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2184\u001b[0m             \u001b[0;31m# build shape is stored since user defined build functions may not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/layers/core/dense.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mlast_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlast_dim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0;34m\"The last dimension of the inputs to a Dense layer \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                 \u001b[0;34m\"should be defined. Found None. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: The last dimension of the inputs to a Dense layer should be defined. Found None. Full input shape received: (0, None)"]}],"source":["# #**\n","# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n","# tf.config.experimental_connect_to_cluster(resolver)\n","# tf.tpu.experimental.initialize_tpu_system(resolver)\n","# print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n","# #**\n","model = Model(args)\n","loss = Loss(args)\n","\n","config = tf.compat.v1.ConfigProto(allow_soft_placement=True)\n","config.gpu_options.allow_growth = True\n","config.graph_options.optimizer_options.global_jit_level = tf.compat.v1.OptimizerOptions.ON_1\n","\n","print(\"Start building model...\")\n","with tf.compat.v1.Session(config=config) as sess:\n","    with tf.device('/cpu:0'):\n","        learning_rate = tf.compat.v1.placeholder(tf.float32, [])\n","        lambda_rec = tf.compat.v1.placeholder(tf.float32, [])\n","\n","        train_op_G = tf.compat.v1.train.AdamOptimizer(\n","            learning_rate=learning_rate, beta1=0.5, beta2=0.9)\n","        train_op_D = tf.compat.v1.train.AdamOptimizer(\n","            learning_rate=learning_rate, beta1=0.5, beta2=0.9)\n","\n","\n","        trainset = tf.compat.v1.data.TFRecordDataset(filenames=[args.trainset_path])\n","        trainset = trainset.shuffle(args.trainset_length)\n","        trainset = trainset.map(parse_trainset, num_parallel_calls=args.workers)\n","        trainset = trainset.batch(args.batch_size).repeat()\n","\n","        train_iterator = trainset.make_one_shot_iterator()\n","        train_im = train_iterator.get_next()\n","\n","        testset = tf.compat.v1.data.TFRecordDataset(filenames=[args.testset_path])\n","        testset = testset.map(parse_testset, num_parallel_calls=args.workers)\n","        testset = testset.batch(args.batch_size).repeat()\n","\n","        test_iterator = testset.make_one_shot_iterator()\n","        test_im = test_iterator.get_next()\n","\n","        print('build model on gpu tower')\n","        models = []\n","        params = []\n","        for gpu_id in range(num_gpu):\n","          with tf.device('/tpu:%d' % gpu_id): #**\n","            print('tower_%d' % gpu_id)\n","            with tf.name_scope('tower_%d' % gpu_id):\n","                with tf.compat.v1.variable_scope('cpu_variables', reuse=gpu_id > 0):\n","\n","                    groundtruth = tf.compat.v1.placeholder(\n","                        tf.float32, [args.batch_size_per_gpu, 128, 256, 3], name='groundtruth')\n","                    left_gt = tf.slice(groundtruth, [0, 0, 0, 0], [args.batch_size_per_gpu, 128, 128, 3])\n","\n","\n","                    reconstruction_ori, reconstruction = model.build_reconstruction(left_gt)\n","                    right_recon = tf.slice(reconstruction, [0, 0, 128, 0], [args.batch_size_per_gpu, 128, 128, 3])\n","\n","                    loss_rec = loss.masked_reconstruction_loss(groundtruth, reconstruction)\n","                    loss_adv_G, loss_adv_D = loss.global_and_local_adv_loss(model, groundtruth, reconstruction)\n","\n","                    reg_losses = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.REGULARIZATION_LOSSES)\n","                    loss_G = loss_adv_G * (1 - lambda_rec) + loss_rec * lambda_rec + sum(reg_losses)\n","                    loss_D = loss_adv_D\n","\n","                    var_G = list(filter(lambda x: x.name.startswith(\n","                        'cpu_variables/GEN'), tf.compat.v1.trainable_variables()))\n","                    var_D = list(filter(lambda x: x.name.startswith(\n","                        'cpu_variables/DIS'), tf.compat.v1.trainable_variables()))\n","\n","\n","                    grad_g = train_op_G.compute_gradients(\n","                        loss_G, var_list=var_G)\n","                    grad_d = train_op_D.compute_gradients(\n","                        loss_D, var_list=var_D)\n","\n","                    models.append((grad_g, grad_d, loss_G, loss_D, loss_adv_G, loss_rec, reconstruction))\n","                    params.append(groundtruth)\n","\n","    print('Done.')\n","\n","    print('Start reducing towers on gpu...')\n","\n","    grad_gs, grad_ds, loss_Gs, loss_Ds, loss_adv_Gs, loss_recs, reconstructions = zip(*models)\n","    groundtruths = params\n","\n","    with tf.device('/tpu:0'): #** gpu\n","        aver_loss_g = tf.reduce_mean(input_tensor=loss_Gs)\n","        aver_loss_d = tf.reduce_mean(input_tensor=loss_Ds)\n","        aver_loss_ag = tf.reduce_mean(input_tensor=loss_adv_Gs)\n","        aver_loss_rec = tf.reduce_mean(input_tensor=loss_recs)\n","\n","        train_op_G = train_op_G.apply_gradients(\n","            loss.average_gradients(grad_gs))\n","        train_op_D = train_op_D.apply_gradients(\n","            loss.average_gradients(grad_ds))\n","\n","        groundtruths = tf.concat(groundtruths, axis=0)\n","        reconstructions = tf.concat(reconstructions, axis=0)\n","\n","        tf.compat.v1.summary.scalar('loss_g', aver_loss_g)\n","        tf.compat.v1.summary.scalar('loss_d', aver_loss_d)\n","        tf.compat.v1.summary.scalar('loss_ag', aver_loss_ag)\n","        tf.compat.v1.summary.scalar('loss_rec', aver_loss_rec)\n","        tf.compat.v1.summary.image('groundtruth', groundtruths, 2)\n","        tf.compat.v1.summary.image('reconstruction', reconstructions, 2)\n","\n","        merged = tf.compat.v1.summary.merge_all()\n","        writer = tf.compat.v1.summary.FileWriter(tensorboard_path, sess.graph)\n","\n","    print('Done.')\n","\n","    iters = 0\n","    saver = tf.compat.v1.train.Saver(max_to_keep=2)\n","    if args.checkpoint_path is None:\n","        sess.run(tf.compat.v1.global_variables_initializer())\n","    else:\n","        print('Start loading checkpoint...')\n","        saver.restore(sess, args.checkpoint_path)\n","        iters = args.resume_step\n","        print('Done.')\n","\n","    print('Start training...')\n","\n","    for epoch in range(args.epoch):\n","\n","        if epoch > args.lr_decay_epoch:\n","            learning_rate_val = args.base_lr / 10\n","        else:\n","            learning_rate_val = args.base_lr\n","\n","        for start, end in zip(\n","                range(0, args.trainset_length, args.batch_size),\n","                range(args.batch_size, args.trainset_length, args.batch_size)):\n","\n","            if iters == 0 and args.checkpoint_path is None:\n","                print('Start pretraining G!')\n","                for t in range(args.warmup_steps):\n","                    if t % 20 == 0:\n","                        print(\"Step:\", t)\n","                    images = sess.run([train_im])[0]\n","                    if len(images) < args.batch_size:\n","                        images = sess.run([train_im])[0]\n","\n","                    inp_dict = {}\n","                    inp_dict = loss.feed_all_gpu(inp_dict, args.num_gpu, args.batch_size_per_gpu, images, params)\n","                    inp_dict[learning_rate] = learning_rate_val\n","                    inp_dict[lambda_rec] = 1.\n","\n","                    _ = sess.run(\n","                        [train_op_G],\n","                        feed_dict=inp_dict)\n","                print('Pre-train G Done!')\n","\n","            if (iters < 25 and args.checkpoint_path is None) or iters % 500 == 0:\n","                n_cir = 30\n","            else:\n","                n_cir = args.critic_steps\n","\n","            for t in range(n_cir):\n","                images = sess.run([train_im])[0]\n","                if len(images) < args.batch_size:\n","                    images = sess.run([train_im])[0]\n","\n","                inp_dict = {}\n","                inp_dict = loss.feed_all_gpu(inp_dict, args.num_gpu, args.batch_size_per_gpu, images, params)\n","                inp_dict[learning_rate] = learning_rate_val\n","                inp_dict[lambda_rec] = args.lambda_rec\n","\n","                _ = sess.run(\n","                    [train_op_D],\n","                    feed_dict=inp_dict)\n","\n","\n","            if iters % 50 == 0:\n","\n","                _, g_val, ag_val, rs, d_val = sess.run(\n","                    [train_op_G, aver_loss_g, aver_loss_ag, merged, aver_loss_d],\n","                    feed_dict=inp_dict)\n","                writer.add_summary(rs, iters)\n","\n","            else:\n","\n","                _, g_val, ag_val, d_val = sess.run(\n","                    [train_op_G, aver_loss_g, aver_loss_ag, aver_loss_d],\n","                    feed_dict=inp_dict)\n","            if iters % 20 == 0:\n","                print(\"Iter:\", iters, 'loss_g:', g_val, 'loss_d:', d_val, 'loss_adv_g:', ag_val)\n","\n","            iters += 1\n","\n","        saver.save(sess, model_path, global_step=iters)\n","\n","        # testing\n","        if epoch > 0:\n","            ii = 0\n","            g_vals = 0\n","            d_vals = 0\n","            ag_vals = 0\n","            n_batchs = 0\n","            for _ in range(int(args.testset_length / args.batch_size)):\n","                test_oris = sess.run([test_im])[0]\n","                if len(test_oris) < args.batch_size:\n","                    test_oris = sess.run([test_im])[0]\n","\n","                inp_dict = {}\n","                inp_dict = loss.feed_all_gpu(inp_dict, args.num_gpu, args.batch_size_per_gpu, test_oris, params)\n","                inp_dict[learning_rate] = learning_rate_val\n","                inp_dict[lambda_rec] = args.lambda_rec\n","\n","                reconstruction_vals, g_val, d_val, ag_val = sess.run(\n","                    [reconstruction, aver_loss_g, aver_loss_d, aver_loss_ag],\n","                    feed_dict=inp_dict)\n","\n","                g_vals += g_val\n","                d_vals += d_val\n","                ag_vals += ag_val\n","                n_batchs += 1\n","\n","                # Save test result every 100 epochs\n","                if epoch % 100 == 0:\n","\n","                    for rec_val, test_ori in zip(reconstruction_vals, test_oris):\n","                        rec_hid = (255. * (rec_val + 1) /\n","                                  2.).astype(np.uint8)\n","                        test_ori = (255. * (test_ori + 1) /\n","                                    2.).astype(np.uint8)\n","                        Image.fromarray(rec_hid).save(os.path.join(\n","                            result_path, 'img_' + str(ii) + '.' + str(int(iters / 100)) + '.jpg'))\n","                        if epoch == 0:\n","                            Image.fromarray(test_ori).save(\n","                                os.path.join(result_path, 'img_' + str(ii) + '.' + str(int(iters / 100)) + '.ori.jpg'))\n","                        ii += 1\n","            g_vals /= n_batchs\n","            d_vals /= n_batchs\n","            ag_vals /= n_batchs\n","\n","            summary = tf.compat.v1.Summary()\n","            summary.value.add(tag='eval/g',\n","                              simple_value=g_vals)\n","            summary.value.add(tag='eval/d',\n","                              simple_value=d_vals)\n","            summary.value.add(tag='eval/ag',\n","                              simple_value=ag_vals)\n","            writer.add_summary(summary, iters)\n","\n","            print(\"=========================================================================\")\n","            print('loss_g:', g_val, 'loss_d:', d_val, 'loss_adv_g:', ag_val)\n","            print(\"=========================================================================\")\n","\n","            if np.isnan(reconstruction_vals.min()) or np.isnan(reconstruction_vals.max()):\n","                print(\"NaN detected!!\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[{"file_id":"https://github.com/csibbitt/NS-Outpainting/blob/master/train_model.ipynb","timestamp":1702613933530}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}